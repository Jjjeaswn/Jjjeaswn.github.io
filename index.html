<!DOCTYPE html>












  


<html class="theme-next muse use-motion" lang="Chinese">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">












<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.4.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.4.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.4.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.4.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '6.4.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta property="og:type" content="website">
<meta property="og:title" content="Jjjeaswn&#39;s blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Jjjeaswn&#39;s blog">
<meta property="og:locale" content="Chinese">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Jjjeaswn&#39;s blog">






  <link rel="canonical" href="http://yoursite.com/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Jjjeaswn's blog</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="Chinese">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jjjeaswn's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />Home</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />Archives</a>
  </li>

      
      
    </ul>
  

  
    

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/08/20/mdp/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jjjeaswn Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jjjeaswn's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/08/20/mdp/" itemprop="url">
                  翻译：强化学习与控制
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-08-20 11:13:00" itemprop="dateCreated datePublished" datetime="2018-08-20T11:13:00+08:00">2018-08-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-08-22 12:15:03" itemprop="dateModified" datetime="2018-08-22T12:15:03+08:00">2018-08-22</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="part-iii-强化学习与控制">Part III 强化学习与控制</h1>
<p>我们现在开始学习强化学习和适应性控制。</p>
<p>在监督学习上，我们的算法尝试去让它们的输出跟训练集中的标签 <span class="math inline">\(y\)</span> 相似。对于每个 <span class="math inline">\(x​\)</span>，标签给出了一个无偏差的“标准答案”。但在很多序列决策和控制问题上，很难提供这样一个显式的监督给学习算法。比如，我们弄了个四条腿的机器人，想尝试编程让它走起来，但起初我们对什么是“正确”的动作，哪些动作能让它走起来没有任何想法，自然而然无法提供给算法显式的监督让它学会行走。</p>
<p>在强化学习框架，我们反过来只提供给我们的算法一个奖励函数，指示它当前做得是好是坏。在上面四条腿行走的例子，如果机器人向前走，激励函数可能给它正面反馈，如果退后或者迭代，激励函数给它负面反馈。如果通过选择动作获取最大的奖励自然就成了算法的任务了。</p>
<p>强化学习有很多成功的应用，包括自动驾驶直升机、机器人腿定位、移动网络路由、市场策略选择、工厂控制和高效的网页索引。我们将会从马尔可夫决策过程（ MDP）的定义开始学习强化学习，它提供强化学习问题里常常拥有的形式。</p>
<h2 id="马尔可夫决策过程mdp">1 马尔可夫决策过程（MDP)</h2>
<p>马尔可夫决策过程（MDP)涉及到这样一组东西 <span class="math inline">\((S,A,\{P_{sa}\},\gamma,R)\)</span></p>
<ul>
<li><p><span class="math inline">\(S\)</span> 是一组<strong>状态</strong>的集合 。（比如，在自动驾驶直升机问题上，<span class="math inline">\(S\)</span>可以是所有直升机位置和朝向的集合。分离散和连续，空间已知）</p></li>
<li><span class="math inline">\(A\)</span> 是一组<strong>动作</strong>的集合。（比如，所有你推动直升机控制杆的所有可能方向。一般是离散的，空间已知）</li>
<li><span class="math inline">\(P_{sa}\)</span>是状态转移概率 。对于每个可能的<span class="math inline">\(s\in S\)</span>和动作<span class="math inline">\(a\in A\)</span>，<span class="math inline">\(P_{sa}\)</span>是一个状态空间上的分布。详情后面我们会讨论，简单地讲，<span class="math inline">\(P_{sa}\)</span>给出如果在状态<span class="math inline">\(s\)</span>的时候我们选择动作<span class="math inline">\(a\)</span>所能达到状态的概率分布。（一般是未知的，或用经验概率近似）</li>
<li><span class="math inline">\(\gamma \in [0,1)\)</span> 称作<strong>折扣因子</strong> （超参数）。</li>
<li><p>$R:S A  $ 是<strong>奖励函数</strong> 。（有时奖励函数只写成状态的函数 $R:S  $ ，奖励函数是已知的）</p></li>
</ul>
<p>MDP的动态过程如下：Agent（动作的执行者）从环境状态 <span class="math inline">\(s_0\)</span> 开始，从动作集合<span class="math inline">\(A\)</span>中选取一个动作<span class="math inline">\(a_0\)</span>。该动作会导致环境状态随机变化，该变化服从<span class="math inline">\(P_{sa}\)</span>这个状态转移概率分布，动作结束后我们得到新的状态<span class="math inline">\(s_1\)</span>, 然后 Agent 再选取一个动作<span class="math inline">\(a_1\)</span>，得到状态<span class="math inline">\(s_2\)</span>， Agent 接着选取<span class="math inline">\(a_2\)</span>… 就这样，我们得到一个序列：</p>
<p><span class="math display">\[
s_0 \xrightarrow {\text{a0}}s_1 \xrightarrow {\text{a1}}s_2 \xrightarrow {\text{a2}}s_3 \xrightarrow {\text{a3}}...
\]</span></p>
<p>遍历上面的状态<span class="math inline">\(s_0,s_1...\)</span>和动作<span class="math inline">\(a_0,a_1...\)</span>，我们定义总的收益 <span class="math display">\[
R(s_0,a_0)+\gamma R(s_1,a_1)+\gamma^2 R(s_2,a_2)+...
\]</span> 或者只看成状态的函数 <span class="math display">\[
R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...
\]</span></p>
<p>为了简化，后续我们只使用“状态-奖励”函数 <span class="math inline">\(R(s)\)</span>，尽管泛化成“（状态-动作)-奖励”函数 <span class="math inline">\(R(s,a)\)</span> 并不十分困难。</p>
<p>在强化学习里，我们的目标是随着时间推进，选择的动作组能最大化总收益的期望： <span class="math display">\[
E[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...]
\]</span> 注意到 <span class="math inline">\(t\)</span> 时刻的奖励被打了折扣 <span class="math inline">\(\gamma^t\)</span>。因此为了期望尽可能的大，我们会希望尽快获取正向的奖励（尽可能推迟负奖励的到来）。在经济领域的应用上，<span class="math inline">\(R(\cdot)\)</span> 可以是利润，此时 <span class="math inline">\(\gamma\)</span> 的一个自然释意是利率（今天的一块钱比未来的一块钱价值更高）。</p>
<p><strong>策略</strong>指任意状态到动作的函数映射 <span class="math inline">\(\pi : S \rightarrow A\)</span>。任何时候我们说<strong>执行</strong>某个策略是指我们按该策略选取动作，即<span class="math inline">\(a=\pi(s)\)</span>。我们同时定义一个策略的状态<strong>值函数</strong>根据以下方程（或者状态动作值函数） <span class="math display">\[
V^\pi(s) = E[R(s_0)+\gamma R(s_1)+\gamma^2 R(s_2)+...|s_0=s,\pi]
\]</span></p>
<p><span class="math inline">\(V^\pi(s)\)</span> 只是根据策略 <span class="math inline">\(\pi\)</span> 从状态<span class="math inline">\(s\)</span>开始的折扣奖励的期望和。</p>
<p>换个角度，一个给定策略 <span class="math inline">\(\pi\)</span> 的值函数 <span class="math inline">\(V^\pi\)</span> 满足<strong>贝尔曼方程组（Bellman Equations）</strong>:</p>
<p><span class="math display">\[
V^\pi(s) = R(s) + \gamma \sum_{s&#39; \in S} P_{s\pi(s)}(s&#39;)V^\pi(s&#39;)
\]</span> 就是说从状态 <span class="math inline">\(s\)</span> 开始折扣奖励的期望和 <span class="math inline">\(V^\pi(s)\)</span> 由两项组成：第一项，<strong>即时奖励</strong> <span class="math inline">\(R(s)\)</span> 我们在开始状态 s 获得的奖励，然后，第二项，未来折扣的奖励与对应状态出现概率乘积之和。更详细地检查第二项，我们看到其中的求和项可以重写成未来状态 <span class="math inline">\(s&#39;\)</span> 其奖励之期望 <span class="math inline">\(E_{s&#39;\sim{P_{s\pi(s)}}}[V^\pi(s&#39;)]\)</span>。其中未来状态 <span class="math inline">\(s&#39;\)</span> 服从分布 <span class="math inline">\(P_{s\pi(s)}\)</span>，该分布是我们从先前状态 <span class="math inline">\(s\)</span> 依据策略执行动作 <span class="math inline">\(\pi(s)\)</span> 之后会得到的。综上，方程的第二项给出MDP第一步动作执行之后，所能获得的折扣奖励期望和。（这里的折扣奖励是指 <span class="math inline">\(\gamma V^\pi(s&#39;)\)</span> ，其实翻译成折扣状态值更恰当，因为并非由奖励函数 <span class="math inline">\(R\)</span> 给出）</p>
<p>我们可以使用贝尔曼方程组高效求解值函数 <span class="math inline">\(V^\pi\)</span>。特别地，在有限状态MDP中（$|S| &lt; $），我们可以为 <span class="math inline">\(V^\pi(s)\)</span> 的每个状态 <span class="math inline">\(s\)</span> 写下一条方程，得到一个 <span class="math inline">\(|S|\)</span> 个变量的 <span class="math inline">\(|S|\)</span> 条方程的方程组，高效求解所有状态的值 <span class="math inline">\(V^\pi(s)\)</span>。（即由于策略已确定， <span class="math inline">\(V^\pi(s_i)\)</span> 可当作变量，<span class="math inline">\(R(s_i)\)</span> 和 <span class="math inline">\(P_{s_i\pi(s_i)}(s_i&#39;)\)</span> 都是常量，其中$ 0 i &lt; |S|, i $）</p>
<p>我们按下面这条公式定义<strong>最优值函数</strong>(即，依照该策略，每个状态都能取到最大的值) <span class="math display">\[
V^*(s) = \max_\pi V^\pi(s)  \tag{1}
\]</span> 换句话讲，这个就是使用任意策略我们能够得到的所有可能中，折扣奖励期望和最大的。下面是贝尔曼方程组版本的最优值函数（跳过策略，直接选取最优动作，使折扣奖励期望和最大）： <span class="math display">\[
V^*(s) = R(s) +  \max_{a \in A} \gamma \sum_{s&#39; \in S} P_{sa}(s&#39;)V^*(s&#39;)  \tag2
\]</span></p>
<p>跟上面一样，第一项是既时的奖励。在所有可以执行的动作 <span class="math inline">\(a\)</span> 中，我们选取能是折扣奖励期望和最大的来执行，第二项是该最优动作带来的折扣奖励期望和。你应该确保自己理解该方程，思考下为什么是这样的。</p>
<p>我们再定义一个策略 <span class="math inline">\(\pi^*: S \rightarrow A\)</span>，如下： <span class="math display">\[
\pi^*(s) = arg \max_{a \in A} \sum_{s&#39; \in S} P_{sa}(s&#39;)V^*(s&#39;) \tag3
\]</span> 注意到， <span class="math inline">\(\pi^*(s)\)</span> 给出的动作 <span class="math inline">\(a\)</span> 在方程(2)中的“max”里面取得最大。</p>
<p>实际上，对于所有的状态和所有的策略，我们有： <span class="math display">\[
V^{\pi^* } (s)= V^*(s) \geq V^\pi(s)
\]</span> 上式等号表明，对于全部状态，策略 <span class="math inline">\(\pi^*\)</span> 的值函数 <span class="math inline">\(V^{\pi^*}\)</span> 等于最优值函数 <span class="math inline">\(V^*\)</span>。另外，大于等于号表明，<span class="math inline">\(\pi^*\)</span> 策略的值至少是跟其他策略的值一样大。换句话说，方程(3)中定义的 <span class="math inline">\(\pi^*\)</span> 是<strong>最优策略</strong>。</p>
<p>值得注意的是，最优策略 <span class="math inline">\(\pi^*\)</span> 有些有趣的性质，它对于全部状态 <span class="math inline">\(s\)</span> 是最优的。确切地说，不会出现当我们从状态 <span class="math inline">\(s\)</span> 开始，得到这个状态某个最优策略，然后从另一个状态 <span class="math inline">\(s&#39;\)</span> 开始，得到另一个最优策略。在方程(1)中，对于全部状态，同一个最优策略 <span class="math inline">\(\pi^*\)</span> 取得最大值。这意味着不管初始状态如何，我们可以使用同一个最优策略 <span class="math inline">\(\pi^*\)</span>。</p>
<h2 id="值迭代与策略迭代">2 值迭代与策略迭代</h2>
<p>下面我们描述两个解决有限状态MDPs的有效算法。现在我们只考虑状态和动作空间有限的MDPs(<span class="math inline">\(|S|&lt;\infty,|A|&lt;\infty\)</span>)。</p>
<p>第一个算法，<strong>值迭代</strong>，如下：</p>
<ol type="1">
<li><p>对于每个状态 <span class="math inline">\(s\)</span>，初始化 <span class="math inline">\(V(s):=0\)</span></p></li>
<li><p>重复直到收敛 { 对每个状态，更新 $V(s) := R(s) + max_{a A} <em>{s’}P</em>{sa}(s’)V(s’) $ }</p></li>
</ol>
<p>此算法可以看成使用 贝尔曼方程 (2) 重复尝试去估计值函数。</p>
<p>有两种可能的方式来执行算法内部循环的更新操作。 第一种是，<strong>同步更新</strong>，我们先算出每个状态 <span class="math inline">\(s\)</span> 对应的新值 <span class="math inline">\(V(s)\)</span>，然后用全部的新值去覆盖掉全部的旧值。这种操作里，算法可以看成实现了把值函数的当前估计映射到新估计上的“贝尔曼拷贝操作(Ballman backup operator)”。第二种是，<strong>异步更新</strong>。我们以某种顺序便利内部循环，每次都更新一个值。</p>
<p>无论哪种，可以证明值迭代可以让 <span class="math inline">\(V\)</span> 收敛到 <span class="math inline">\(V^*\)</span>。有了 <span class="math inline">\(V^*\)</span> 我们可以用方程(3)得出最优策略。</p>
<p>除了值迭代，还有第二个标准算法，<strong>策略迭代</strong>，可用于找到MDPs的最优策略。算法如下：</p>
<ol type="1">
<li>随机初始化策略 <span class="math inline">\(\pi\)</span>。</li>
<li>重复直至收敛 {
<ol type="a">
<li>让 <span class="math inline">\(V:=V^{\pi}\)</span></li>
<li>对于每个状态 <span class="math inline">\(s\)</span>，让 <span class="math inline">\(\pi(s) := arg \max_{a \in A} \sum_{s&#39;} P_{sa}(s&#39;) V(s&#39;)\)</span>。 }</li>
</ol></li>
</ol>
<p>因此，在内部循环重复计算当前策略的值函数，然后用当前值函数更新策略（步骤(b)中找到的策略也叫关于值函数 <span class="math inline">\(V\)</span> 的贪心策略）。注意到步骤(a)可以用先前提到的求贝尔曼方程线性方程组的方式求解，对于特定的策略来讲，这只是一组拥有 <span class="math inline">\(|S|\)</span> 个变量的 <span class="math inline">\(|S|\)</span> 条方程的方程组。</p>
<p>在此算法进行最多有限次数的迭代后，<span class="math inline">\(V\)</span> 将会收敛到 <span class="math inline">\(V^*\)</span>，此时对应的 <span class="math inline">\(\pi\)</span> 收敛到 <span class="math inline">\(\pi^*\)</span> 。</p>
<p>值迭代跟策略迭代都是解决马尔可夫决策过程的标准算法，关于哪个算法更好现在并没有统一的定论。对于小规模的的马尔可夫决策过程，策略迭代通常很快，很少几次迭代即可收敛。不过，对于拥有较大状态空间的马尔可夫决策过程，在显式求解 <span class="math inline">\(V^\pi\)</span> 的一系列大的线性方程组上会遇到困难。在这些问题上，值迭代可能被优先考虑。因此，在实践中，似乎值迭代比策略迭代用得更频繁。</p>
<h2 id="学习mdp模型">3 学习MDP模型</h2>
<p>目前为止，我们讨论的马尔可夫决策过程和求解算法都是假设状态转移概率和奖励是已知的。在很多现实问题中，没有显示的状态转移概率和奖励提供，我们需要从数据里估算它们。（通常，<span class="math inline">\(S\)</span>，<span class="math inline">\(A\)</span> 和 <span class="math inline">\(\gamma\)</span> 是已知的）</p>
<p>比如，假设，对于倒立摆问题（参考问题集4），我们拿到一定数量的马尔可夫决策过程的试验，如下：</p>
<p><span class="math display">\[
\begin{array}
\ s^{(1)}_0 \xrightarrow {a^{(1)}_0}s^{(1)}_1 \xrightarrow {a^{(1)}_1}s^{(1)}_2 \xrightarrow {a^{(1)}_2}s^{(1)}_3 \xrightarrow {a^{(1)}_3} \ldots \\
s^{(2)}_0 \xrightarrow {a^{(2)}_0}s^{(2)}_1 \xrightarrow {a^{(2)}_1}s^{(2)}_2 \xrightarrow {a^{(2)}_2}s^{(2)}_3 \xrightarrow {a^{(2)}_3} \ldots \\
\ldots
\end{array}
\]</span></p>
<p>这里 <span class="math inline">\(s_i^{(j)}\)</span> 是我们第 <span class="math inline">\(j\)</span> 次试验在时间 <span class="math inline">\(i\)</span> 的状态。 <span class="math inline">\(a_i^{(j)}\)</span> 是在该状态我们选择的对应动作。实际上，每次试验都会一直执行，直到马尔可夫决策过程终止（比如在倒立摆问题上杆倒了），或者执行有限的次数。</p>
<p>有了在MDP上获得的一组试验组成的“经验”，我们可以很容易获得状态转换概率的极大似然近似估计： <span class="math display">\[
P_{sa}(s&#39;) = \frac{\#我们在状态{s}执行动作a到达{s&#39;}的次数}{\#我们在状态s执行动作a的次数} \tag4
\]</span> 或者，如果上面的比例是 “0/0”——对应之前从未在状态 <span class="math inline">\(s\)</span> 选择执行动作 <span class="math inline">\(a\)</span> —— 我们可以简单地估计 $P_{sa}(s’) $ 为 <span class="math inline">\(1/|S|\)</span> 。（也就是，认为 <span class="math inline">\(P_{sa}\)</span> 在所有状态上服从均匀分布）</p>
<p>注意到，如果我们在马尔可夫决策过程中获得更多的经验，这里有一个有效的方式用这些新的经验去更新我们的状态转移概率。具体，我们我们保持持有（4）中的分子跟分母的计数，然后当观察到更多的尝试时，可以简单地把新值累计进入就行。计算这些计数的比值就可以拿到我们的 <span class="math inline">\(P_{sa}\)</span> 的估计。</p>
<p>使用相同的过程，如果 <span class="math inline">\(R\)</span> 是未知的，我们可以拿在状态 <span class="math inline">\(s\)</span> 的的平均奖励作为状态 <span class="math inline">\(s\)</span> 的即刻奖励的期望值。</p>
<p>在学到MDP的一个模型后，既拥有状态转移概率和奖励函数的估计，我们可以利用值迭代或者策略迭代求解该MDP。举个例子，把模型学习跟值迭代放在一起，我们得到一个可能的算法用于求解未知状态转移概率的MDP：</p>
<ol type="1">
<li><p>随机初始化策略 <span class="math inline">\(\pi\)</span></p></li>
<li><p>重复 {</p>
<p>（a） 按策略 <span class="math inline">\(\pi\)</span> 执行一定次数的试验。</p>
<p>（b）使用MDP过程的累积经验，更新我们的估计 <span class="math inline">\(P_{sa}\)</span> （和 <span class="math inline">\(R\)</span>， 如果适用的话）。</p>
<p>（c）用估计的状态转移概率和奖励函数进行值迭代，获得一个新的值函数的估计 <span class="math inline">\(V\)</span>。</p>
<p>（d）用关于值函数 <span class="math inline">\(V\)</span> 贪婪的方式，更新策略 <span class="math inline">\(\pi\)</span> 。</p>
<p>}</p>
<p>我们注意到，对于这个特定的算法有一个简单的优化可以让它跑得更快。具体，在算法的内部循环，我们执行值迭代的地方，我们可以用上一次循环得到的结果来初始化值函数 <span class="math inline">\(V\)</span> ，取代零初始化，这会给算法一个更好的起点，收敛更快。</p></li>
</ol>
<h2 id="连续状态下的mdps">4 连续状态下的MDPs</h2>
<p>到目前为止，我们仅关注有限状态的马尔可夫决策过程。下面开始讨论适用于拥有无限状态的马尔可夫决策过程的算法。举个例子，对于一辆车，我们可能用 <span class="math inline">\((x,y,\theta,\vec x, \vec y, \vec \theta)\)</span> 来表示它的状态，其中它的位置 <span class="math inline">\((x,y)\)</span>；朝向 <span class="math inline">\(\theta\)</span>；在 <span class="math inline">\(x\)</span> 和 <span class="math inline">\(y\)</span> 方向的速度 <span class="math inline">\(\vec x\)</span> 和 <span class="math inline">\(\vec y\)</span> ；以及角速度 <span class="math inline">\(\vec \theta\)</span>。因此，<span class="math inline">\(S = \mathbb{R}^6\)</span> 这组状态集合是无限的，因为对于车辆的位置和朝向是有无限个可能值的。相似地，你在PS4上看到的倒立摆游戏有状态 <span class="math inline">\((x,\theta\,\vec x, \vec \theta)\)</span>，其中 <span class="math inline">\(\theta\)</span> 是杆的角度。又或者，在三维空间中飞行的直升飞机拥有 <span class="math inline">\((x,y,z,\phi, \theta, \psi, \vec x, \vec y, \vec z, \vec \phi, \vec \theta, \vec \psi)\)</span> 形式的状态，其中这里的 <span class="math inline">\(\phi\)</span> 、<span class="math inline">\(\theta\)</span> 和 <span class="math inline">\(\psi\)</span> 指定了直升飞机的空间朝向。</p>
<p>在这个章节，我们将考虑状态空间是 <span class="math inline">\(S = \mathbb{R}^n\)</span> 的设置，然后阐述解决这类MDP的方法。</p>
<h3 id="离散化">4.1 离散化</h3>
<p>将连续状态MDP问题中的状态空间离散化可能是最简单的方式了，然后用上面的值迭代或策略迭代求解。</p>
<p>比如，对于二维的状态 <span class="math inline">\((s_1,s_2)\)</span>，我们可以使用格子来离散化状态空间：</p>
<figure>
<img src="assets/mdp_img1.png" alt="Fig.1"><figcaption>Fig.1</figcaption>
</figure>
<p>这里，每个格子表示一个单独的离散状态 <span class="math inline">\(\bar{s}\)</span> 。接着我们可以通过离散的 <span class="math inline">\((\bar{S}, A, \{P_{\bar{s}a} \}, \gamma, R )\)</span>，其中 <span class="math inline">\(\bar{S}\)</span> 是离散状态集合。<span class="math inline">\(\{ P_{\bar{s}a} \}\)</span> 是我们在离散空间上的状态转移概率。我们可以用值迭代或者策略迭代求解最优值函数 <span class="math inline">\(V^*(\bar{s})\)</span> 或者最优策略 <span class="math inline">\(\pi^*(\bar{s})\)</span> 。当我们的真实系统处在某个连续值状态 <span class="math inline">\(s \in S\)</span> 中时，我们需要选择一个动作去执行，我们计算对应的离散状态 <span class="math inline">\(\bar{s}\)</span>，然后执行动作 <span class="math inline">\(\pi^*(\bar{s})\)</span> 。</p>
<p>在很多问题上，离散方法是可行的。不过有两个缺点。第一，它得到的结果 <span class="math inline">\(V^*\)</span> (或者 <span class="math inline">\(\pi^*\)</span>) 都是对实际问题相当naive的简化。确切地说，它假设值函数在每个离散的区间中得到一个固定的值。</p>
<p>为了更好地理解上述假设的局限，可以考虑一个监督学习问题，去拟合下图的数据集：</p>
<figure>
<img src="assets/mdp_img2.png" alt="Fig.2"><figcaption>Fig.2</figcaption>
</figure>
<p>如你所见，线性回归应该可以很好地解决此问题。但是，如果我们对 x 轴进行离散表示，并规定每个离散区间只能对应一个固定值，我们拟合的结果看起来就像：</p>
<figure>
<img src="assets/mdp_img3.png" alt="Fig.3"><figcaption>Fig.3</figcaption>
</figure>
<p>对于很多光滑的函数，这样每个区间有个固定值的并不能很好表示它们。如此一来结果会很粗糙，在不同的区间泛化效果也不理想。用这样的方式，我们可能需要很细微的颗粒度（每个格子都足够小）才能得到一个比较好的近似结果。</p>
<p>另一个缺点是这样的表示会导致纬度诅咒。假设 <span class="math inline">\(S = \mathbb{R}^n\)</span> ，我们把这 n 维状态每个都离散成 k 个值。这时我们得到的状态空间值的总个数是 <span class="math inline">\(k^n\)</span> 。总个数是随 n 指数级增长的，因此无法很好地适用大规模的问题。例如，有个10维的状态，如果我们把每个纬度都离散成100个值，我们有 $100^{10} = 10^{20} $个状态值，对于现在的桌面计算机来说太大了。</p>
<p>根据经验，对于1维、2维的问题离散方法能很好地工作（而且有简单易于实现的优点）。也许有一些更聪明的方法，更小心地选择离散的方式，离散方法在3维、4维的问题上也能行。如果你特别聪明，然后又特别地幸运，你说不定可以用它解决6维的问题。但是更高纬度的问题，可能就无能为力了。</p>
<h3 id="值函数近似">4.2 值函数近似</h3>
<p>我们现在讲一种在连续状态下寻找马尔可夫决策过程最佳策略的替代方法，我们不用离散而是直接近似 <span class="math inline">\(V^*\)</span> 。值函数近似的方法已经在很多强化学习的问题中有成功的例子。</p>
<h4 id="使用模型或模拟器">4.2.1 使用模型或模拟器</h4>
<p>去开发值函数近似的方法，我们会先假设有一个<strong>模型</strong>或者<strong>模拟器</strong>。简单地讲，我们可以将模拟器堪称一个黑盒，它接受一个任意状态的值（连续值） <span class="math inline">\(s_t\)</span> 和动作 <span class="math inline">\(a_t\)</span>，然后根据状态转移概率 <span class="math inline">\(P_{s_t a_t}\)</span> 返回下一个状态 <span class="math inline">\(s_{t+1}\)</span> 。</p>
<figure>
<img src="assets/mdp_img4.png" alt="Fig.4"><figcaption>Fig.4</figcaption>
</figure>
<p>有很多途径可以得到这样一个模型，之一是使用物理模拟器。比如，在倒立摆问题中，已知 <span class="math inline">\(t\)</span> 时刻的状态和选择执行的动作 <span class="math inline">\(a\)</span>，假设我们知道整个系统的参数（摆杆的长度、质量等），模拟器使用物理定律计算小车／摆杆在时刻 <span class="math inline">\(t + 1\)</span> 的位置和朝向。使用现成的软件包，提供机械系统的完整描述、当前状态 <span class="math inline">\(s_t\)</span> 和动作 <span class="math inline">\(a_t\)</span>，我们可以计算未来很短时间内的状态 <span class="math inline">\(s_{t+1}\)</span> 。</p>
<p>另一种方式是从马尔可夫决策过程中收集数据学习，得到一个模型。比如我们进行了 <span class="math inline">\(m\)</span> 次<strong>试验</strong>，每次试验里我们都重复选取动作执行 <span class="math inline">\(T\)</span> 个时刻。选取动作可以是随机、通过某种策略或通过其他途径。然后我们观察到如下 m 个状态序列：</p>
<p><span class="math display">\[
\begin{array}
\ s^{(1)}_0 \xrightarrow {a^{(1)}_0}s^{(1)}_1 \xrightarrow {a^{(1)}_1}s^{(1)}_2 \xrightarrow  {a^{(1)}_2} \ldots  \xrightarrow {a^{(1)}_{T-1}} s^{(1)}_T \\
\ s^{(2)}_0 \xrightarrow {a^{(2)}_0}s^{(2)}_1 \xrightarrow {a^{(2)}_1}s^{(2)}_2 \xrightarrow  {a^{(2)}_2} \ldots  \xrightarrow {a^{(2)}_{T-1}} s^{(2)}_T \\
\ldots \\
\ s^{(m)}_0 \xrightarrow {a^{(m)}_0}s^{(m)}_1 \xrightarrow {a^{(m)}_1}s^{(m)}_2 \xrightarrow  {a^{(m)}_2} \ldots  \xrightarrow {a^{(m)}_{T-1}} s^{(m)}_T \\
\end{array}
\]</span> 我们可以把 <span class="math inline">\(s_{t+1}\)</span> 作为 <span class="math inline">\(s_t\)</span> 和 <span class="math inline">\(a_t\)</span> 的函数，用学习算法预测它。</p>
<p>比如，某人可能选择学习一个跟线性回归相似的线性模型</p>
<p><span class="math display">\[
s_{t+1}= As_t + Ba_t \tag 5
\]</span></p>
<p>这里，模型的参数是矩阵 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> ，可以用上面收集的数据估计它们</p>
<p><span class="math display">\[
arg \min_{A,B} \sum_{i=1}^m \sum_{t=0}^{T-1}||s_{t+1}^{(i)} - (As_t^{(i)} + Ba_t^{(i)})||
\]</span></p>
<p>(这里对应参数的极大似然估计)</p>
<p>学到 <span class="math inline">\(A\)</span> 和 <span class="math inline">\(B\)</span> 之后，可以建立一个<strong>确定</strong>模型，在确定模型中，给定 <span class="math inline">\(s_t\)</span> 和 <span class="math inline">\(a_t\)</span> 输入 <span class="math inline">\(s_{t+1}\)</span> 是固定的。确切地讲，我们总是通过（5）计算 <span class="math inline">\(s_{t+1}\)</span> 。另外我们也可以建立一个<strong>随机</strong>模型，将 <span class="math inline">\(s_{t+1}\)</span> 作为输入的随机函数，建模如下： <span class="math display">\[
s_{t+1}  = As_t + Ba_t + \epsilon_t
\]</span> 其中 <span class="math inline">\(\epsilon_t\)</span> 是噪音项，通常取 <span class="math inline">\(\epsilon_t \cal {\sim} N( \rm 0, Σ)\)</span> 。（其中 协方差矩阵 <span class="math inline">\(Σ\)</span> 也可以用收集的数据直接估计 ）</p>
<p>这里，我们把下一个状态 <span class="math inline">\(s_{t+1}\)</span> 写成当前状态和动作的线性函数；当然，非线性函数也是可行的。确切地，可以学习一个模型 <span class="math inline">\(s_{t+1} = A\phi_s{s_t} + B\phi_a(a_t)\)</span> ，其中 <span class="math inline">\(\phi_s\)</span> 和 <span class="math inline">\(\phi_a\)</span>是状态和动作的非线性映射。另外也可以使用非线性算法，比如局部权重线性回归，把 $s_{t+1} $ 作为 <span class="math inline">\(s_t\)</span> 和 <span class="math inline">\(a_t\)</span> 的函数来学习估计。用这些方法都可以建立确定或随机模型。</p>
<h4 id="拟合值迭代">4.2.2 拟合值迭代</h4>
<p>现在我们描述用于近似连续状态MDP过程中值函数的<strong>拟合值迭代</strong>算法。方便继续，我们假设问题处在一个连续的状态空间 <span class="math inline">\(S = \mathbb{R}^n\)</span> ，但是动作空间 <span class="math inline">\(A\)</span> 很小而且是离散的。</p>
<p>回想一下，在值迭代中，我们执行更新 <span class="math display">\[
V(s) := R(s) + \lambda \max_a\int P_{sa}(s&#39;)V(s&#39;)ds&#39; \tag 6 \\
\]</span></p>
<p><span class="math display">\[
= R(s)+ \lambda \max_a E_{s&#39; \sim P_{sa} } [ V(s&#39;)] \tag7
\]</span></p>
<p>(在第2章节中，我们是写成求和的形式，而不是这里的积分形式；新的记号法表示我们正在处理连续的状态空间)</p>
<p>拟合值迭代的主要想法是在有限的状态样本 <span class="math inline">\(s^{(1)}, \dots, s^{(m)}\)</span>上，近似地计算上面的更新值。在下面我们将使用监督学习的算法——线性回归——来近似值函数，此时将值函数看作是状态的线性或非线性函数： <span class="math display">\[
V(s) = \theta^T \phi(s)
\]</span> 这里的 <span class="math inline">\(\phi\)</span> 是状态的某个适当映射。</p>
<p>对于每个状态值 <span class="math inline">\(s(i)\)</span> ，拟合值迭代会先计算一个量 <span class="math inline">\(y(i)\)</span> ，这个我们对 $ R(s)+ <em>a E</em>{s’ P_{sa} } [ V(s’)] $ 的近似（方程7的右手边）。然后它用监督学习的方式去尝试让 <span class="math inline">\(V(s)\)</span> 靠近 $ R(s)+ <em>a E</em>{s’ P_{sa} } [ V(s’)] $ (换句话说，让 $V(s) $ 靠近 <span class="math inline">\(y(i)\)</span>) 。</p>
<p>具体算法如下：</p>
<ol type="1">
<li><p>随机取 m 个状态样本 <span class="math inline">\(s^{(1)}, \dots, s^{(m)} \in S\)</span></p></li>
<li><p>初始化 <span class="math inline">\(\theta := 0\)</span></p></li>
<li><p>重复 {</p>
<p>对于 $i = 1, … , m $ {</p>
<p>对于每个动作 <span class="math inline">\(a \in A\)</span> {</p>
<p>取样 $ s’, \dots, s’_k P_{s^{(i)}a} $ (使用MDP模型)</p>
<p>让 $ q(a) = 1/k ^k_{j=1} (R(s^{(i)}) + V(s’_j))$</p>
<p>// 也就是, $ R(s)+ E_{s’ P_{sa} } [ V(s’)] $</p>
<p>}</p>
<p>令 <span class="math inline">\(y(i) = max_a q(a)\)</span></p>
<p>// 也就是， $ R(s)+ <em>a E</em>{ s’ P_{sa} } [ V(s’)] $</p>
<p>}</p>
<p>// 在原始版本的值迭代算法（离散状态上的）</p>
<p>// 我们根据 <span class="math inline">\(V(s^{(i)}) : = y^{(i)}\)</span> 更新值函数</p>
<p>// 在这个算法，我们通过监督学习（线性回归)</p>
<p>// 达到我们想要的 <span class="math inline">\(V(s^{(i)}) \approx y^{(i)}\)</span></p>
<p>让 <span class="math inline">\(\theta : = arg \min_\theta 1/2 \sum_{i=1}^m( \theta^T \phi(s^{(i)}) - y^{(i)} )^2\)</span></p></li>
</ol>
<p>}</p>
<p>上述，我们使用线性回归写出拟合值迭代算法，尝试让 $V(s^{(i)}) $ 靠近 <span class="math inline">\(y^{(i)}\)</span> 。这一步跟标准的监督学习完全相似，在监督学习里我们有一个训练集 $(x^1, y^1),(x^2, y^2),(x^3, y^3) , \dots, (x^m, y^m) $， 想学习一个 x 到 y 的函数映射；唯一的区别是这里 s 取代了 x。 虽然上面我们用了线性回归，但其他回归算法也是可行的（比如，局部权重线性回归）。</p>
<p>跟值迭代不一样的是，拟合值迭代并不能被证明总是收敛的。不过，在实际应用过程中，它确实经常收敛（或接近收敛），而且在很多问题上表现良好。值得注意的是，如果我们使用确定性的MDP模拟器或模型，拟合值迭代可以简化到 <span class="math inline">\(k = 1\)</span> 的形式。这时因为在确定性模型中，一个样本已经足够获取奖励的期望。对于非确定性模型，我们需要 k 个样本，用它们的均值来近似期望（注意算法伪代码里$ q(a) $的定义）。</p>
<p>最后，拟合值迭代给出的值函数 V 近似最优值函数 <span class="math inline">\(V^*\)</span> 。这里隐式子定义了我们的策略。具体地，当我们的系统处在状态 <span class="math inline">\(s\)</span> 时，我们根据下面式子选择动作 <span class="math inline">\(a\)</span> <span class="math display">\[
arg \max_a E_{s&#39; \sim P_{sa}}[V(s&#39;)] \tag 8
\]</span> 这个计算过程跟拟合值÷迭代算法的内部循环相似，对于每个动作，我们采集 k 个样本 <span class="math inline">\(s&#39;_1,s&#39;_2, \dots, s&#39;_k \sim P_{sa}\)</span> 来近似地计算期望。（再次提醒，如果是确定性模型，让 k =1 ）</p>
<p>实际操作中，也有其他的方法来近似这一步。比如，一个非常普遍的例子，如果我们的模拟器的形式是 <span class="math inline">\(s_{t+1} = f(s_t,a_t) + \epsilon_t\)</span> ，其中 <span class="math inline">\(f\)</span> 是某个确定函数（比如， <span class="math inline">\(f(s_t,a_t) = As_t + ba_t\)</span>），<span class="math inline">\(\epsilon_t\)</span> 是高斯噪音。在这个例子，我们可以选取动作 <span class="math display">\[
arg \max_a(V(f(s,a)))
\]</span> 换句话说，我们简单的忽略掉噪音项，让 <span class="math inline">\(\epsilon = 0\)</span>， <span class="math inline">\(k = 1\)</span>。 等价地，这个可以用方程8推导出来 <span class="math display">\[
E_{s&#39;}(V(s&#39;)) \approx V(E_{s&#39;}(s&#39;)) \tag 9 \\
\]</span> <span class="math display">\[
= V(f(s,a)) \tag {10}
\]</span></p>
<p>其中这里的期望是在随机的 <span class="math inline">\(s&#39; \sim P_{sa}\)</span> 上的。所以只要噪音项不是很大，这通常是个合理的近似。<br>
但是，对于不能使用该近似方法的问题，我们不得不去采集 <span class="math inline">\(k|A|\)</span> 个样本（使用模型），去近似上面的期望，这样的计算量会大很多。</p>
<p>原文 <a href="http://cs229.stanford.edu/notes/cs229-notes12.pdf" target="_blank" rel="noopener">CS229 Lecture notes Part XIII</a><br>
是该课程的一部分<a href="http://cs229.stanford.edu/syllabus.html" target="_blank" rel="noopener">CS229 lecture 16 - 18</a><br>
视频（油管）<a href="https://www.youtube.com/watch?v=RtxI449ZjSc" target="_blank" rel="noopener">CS229 Lecture by Andrew Ng</a></p>
<blockquote>
<p>译者注：懒癌发作，翻译完成于 2018年八月20号 上午 11:33，历时一个月。</p>
</blockquote>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/20/ng/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jjjeaswn Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jjjeaswn's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/20/ng/" itemprop="url">
                  机器学习课程分享
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-07-20 18:24:05" itemprop="dateCreated datePublished" datetime="2018-07-20T18:24:05+08:00">2018-07-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-08-20 18:47:23" itemprop="dateModified" datetime="2018-08-20T18:47:23+08:00">2018-08-20</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/课程介绍/" itemprop="url" rel="index"><span itemprop="name">课程介绍</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="machine-learning">Machine Learning</h1>
<p>分享的是<a href="https://www.coursera.org/learn/machine-learning" target="_blank" rel="noopener">NG大神的机器学习课程</a>，学习该课程将需要<em>11周</em>。</p>
<p>这个课程我是两年前（2016）上过的，当时的Coursera还没现在这么抠门。Andrew NG的全英视频，听不懂的可以开字幕。课程内容主要是传统的机器学习／模式识别，看材料、视频和用matlab做些小作业（课程期间提供免费的授权证书）。</p>
<p>第一周学习单变量线性回归，会带你复习一下线性代数。</p>
<p>第二周学习多变量线性回归，搭配matlab／octave的使用教程。</p>
<p>第三周学习逻辑回归，逻辑回归虽然叫回归，但实打实是个分类器（Classifier)。实际上，从代价函数的角度看，分类跟回归是一样的，区别在于分类的输出值是离散的，回归的输出值是连续的。</p>
<p>第四、五周学习神经网络，梯度下降和反向传播算法，随机初始化参数。</p>
<p>第六周学习如何选择、训练、诊断模型，学会看学习曲线和如何决定下一步做什么来改善你的模型；讨论机器学习系统的设计问题，先做什么，后做什么，权衡准确率和召回率。</p>
<p>第七周学习支持向量机。</p>
<p>第八周学习K-Means和PCA两个无监督学习算法，理解无监督学习的目的和动机，以及如何选择指定聚类数量和主要成分数量。</p>
<p>第九周学习异常检测、基于内容的推荐系统及协同过滤算法，这里涉及到低秩矩阵的分解和一个技巧（Mean Normalization，均值规范化）。</p>
<p>第十周学习面对大规模数据量时的机器学习算法实现，主要内容包括随机梯度下降、迷你批量梯度下降、在线学习和分布式数据处理（Map Reduce）。</p>
<p>第十一周是个应用栗子，图片OCR（光学字符识别），如何构建一个能够识别图片上物体、文字和数字的工作流（Pipeline）。图片检测上会讲弱智的滑动窗口，然后是如何获取数据，如何增强你的数据集以及遇到瓶颈的时候该怎么处理。</p>
<p>最后是，恭喜你完成课程！</p>
<p>2018年7月18日 13:40</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/20/ml-dl/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jjjeaswn Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jjjeaswn's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/20/ml-dl/" itemprop="url">
                  理论知识目录
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-07-20 12:13:54" itemprop="dateCreated datePublished" datetime="2018-07-20T12:13:54+08:00">2018-07-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-08-20 18:25:09" itemprop="dateModified" datetime="2018-08-20T18:25:09+08:00">2018-08-20</time>
              
            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="机器学习-深度学习の自学手册">机器学习 &amp; 深度学习の自学手册</h1>
<blockquote>
<p>本博客不定期更新</p>
</blockquote>
<h2 id="机器学习">机器学习</h2>
<ul>
<li>监督学习
<ul>
<li>标签数据</li>
<li>分类问题</li>
<li>回归问题</li>
</ul></li>
<li>非监督学习
<ul>
<li>聚类分析</li>
<li>数据降维</li>
</ul></li>
<li>增强学习
<ul>
<li>离散问题</li>
<li>马可夫决策过程（MDP)
<ul>
<li>值迭代<br>
</li>
<li>策略迭代</li>
</ul></li>
<li>Q值学习</li>
<li>连续问题</li>
<li>深度Q值网络</li>
</ul></li>
</ul>
<h2 id="深度学习">深度学习</h2>
<ul>
<li>卷积神经网络（CNN）
<ul>
<li>卷积核</li>
<li>卷积运算</li>
</ul></li>
<li>循环神经网络（RNN）
<ul>
<li>循环神经网络の细胞（RNNCell）</li>
<li>时间上的反向传播</li>
<li>长短期记忆神经元（LSTM)</li>
<li>门循环神经网络神经元（GRU）</li>
</ul></li>
<li>编码器-解码器模型
<ul>
<li>应用
<ul>
<li>机器翻译</li>
<li>人机对话</li>
</ul></li>
</ul></li>
<li>注意力模型（Attention Model）
<ul>
<li>在计算机图形上</li>
<li>改善编码器-解码器模型</li>
<li>实现
<ul>
<li>软注意力（Soft）</li>
<li>硬注意力（Hard）</li>
</ul></li>
</ul></li>
</ul>
<h2 id="工具python">工具（Python）</h2>
<ul>
<li>机器学习
<ul>
<li>numpy</li>
<li>pandas</li>
<li>matplotlib</li>
<li>scikit-learn</li>
</ul></li>
<li>深度学习
<ul>
<li>tensorflow</li>
<li>keras</li>
</ul></li>
</ul>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/07/20/avatar-features/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Jjjeaswn Wong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jjjeaswn's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/07/20/avatar-features/" itemprop="url">
                  如何使用预训练的CNN网络提取图片特征
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2018-07-20 12:13:54" itemprop="dateCreated datePublished" datetime="2018-07-20T12:13:54+08:00">2018-07-20</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2018-08-20 18:50:55" itemprop="dateModified" datetime="2018-08-20T18:50:55+08:00">2018-08-20</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习/应用/" itemprop="url" rel="index"><span itemprop="name">应用</span></a></span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="如何使用预训练的cnn网络提取图片特征">如何使用预训练的CNN网络提取图片特征</h1>
<h2 id="想法-动机">想法 &amp; 动机</h2>
<p>同事最近获取了一批微信用户数据，决定挖一挖里面潜在的内容。先是用 <code>Face++</code> 跑了一遍性别、年龄，但发现很多人的头像并不是他们本人，甚至不是人物，就算是本人也是严重后期过的，跑出来的解决没多大参考意义。于是我们仔细翻阅了一批样本图片，发现其实每个人设置头像的出发点可能不同，但却并非无迹可寻，大致可以分为：</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">自拍</th>
<th style="text-align: center;">风景</th>
<th style="text-align: center;">佛 &amp; 非主流</th>
<th style="text-align: center;">其他</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">土豪大叔自拍</td>
<td style="text-align: center;">低档风景</td>
<td style="text-align: center;">辣眼睛艺术字体</td>
<td style="text-align: center;">宠物</td>
</tr>
<tr class="even">
<td style="text-align: center;">圣光自拍</td>
<td style="text-align: center;">小清新风景</td>
<td style="text-align: center;">化妆品</td>
<td style="text-align: center;">动物</td>
</tr>
<tr class="odd">
<td style="text-align: center;">小清新自拍</td>
<td style="text-align: center;">高档风景</td>
<td style="text-align: center;">南无哦弥陀佛</td>
<td style="text-align: center;">卡通人物</td>
</tr>
<tr class="even">
<td style="text-align: center;">油腻大叔自拍</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">小朋友头像</td>
</tr>
</tbody>
</table>
<p>你也发现了，类别还能继续分下去。显然用人工的方式是没办法继续的，或者继续的成本太高，老板会把我炒掉。因为他可能突然提一个新需求“我们现在有一款新商品，你去抓堆优质用户出来，ddl明天。”</p>
<p>在接下去做下面的工作之前，首先声明一点，我是基于这样一种信念去做的：</p>
<p>“其实人都特别不到哪里去”</p>
<p>会用小朋友做头像的，大部分是妈妈吧。不管是年前的妈妈，还是中年的妈妈。我的朋友圈验证了这一点，或者说我基于自己的生活经验在猜测。</p>
<p><strong>好</strong></p>
<p>下面进入正题，如何使用预训练的CNN网络提取图片特征。</p>
<h2 id="预训练网络pre-trained-network">预训练网络（Pre-trained network)</h2>
<p>现在的神经网络都很大，参数很多，虽然我们可以用 <code>Keras</code> 很快写出一个模型，但是把这个模型调到能用还是…算了。</p>
<p>老板不充钱，没GPU云服务器用☹️☹️</p>
<p>好在很多我们耳熟能详的CNN网络都放出预先训练好的权重，我们可以直接下载下来，load到模型里，直接做预测，跳过训练的阶段。</p>
<p>开源大法好😘</p>
<p>除了做预测任务，我们还能截取网络的中间层结果。卷机神经网络的中间层结果可以被当作图片的<code>特征</code>使用。然后我现在想用这些<code>特征</code>来粗略地代表每个实实在在的<code>用户</code>，并把他们<code>分类</code>。</p>
<p>我选择的是<code>XceptionNet</code>。</p>
<h2 id="截取中间结果">截取中间结果</h2>
<p>直接贴代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.applications.xception <span class="keyword">import</span> Xception</span><br><span class="line"><span class="keyword">from</span> keras.applications.xception <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> image</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">base_model = Xception(weights=<span class="string">'imagenet'</span>) <span class="comment"># 这一步会自动下载预训练的权重文件</span></span><br><span class="line"></span><br><span class="line">print(base_model.summary()) <span class="comment"># 你可以调用该方法查看以下网络的结构</span></span><br><span class="line"></span><br><span class="line">model = Model(inputs=base_model.input, outputs=base_model.get_layer(<span class="string">'avg_pool'</span>).output) <span class="comment"># 截取 avg_pool 层的输出</span></span><br><span class="line"></span><br><span class="line">limit = <span class="number">1000</span> <span class="comment"># 样本数量</span></span><br><span class="line">X_img = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> img <span class="keyword">in</span> random.sample(os.listdir(<span class="string">'imgs'</span>), limit):</span><br><span class="line">	print(img)</span><br><span class="line">	img_path = <span class="string">'imgs/'</span> + img</span><br><span class="line">	img = image.load_img(img_path, target_size=(<span class="number">299</span>, <span class="number">299</span>))</span><br><span class="line">	x = image.img_to_array(img)</span><br><span class="line">	X_img.append(x)</span><br><span class="line"></span><br><span class="line">X_img = preprocess_input(np.array(X_img))</span><br><span class="line">img_features = model.predict(X_img, batch_size=<span class="number">10</span>, verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">features_high_dim = []</span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> img_features:</span><br><span class="line">  features_high_dim.append(f.flatten()) <span class="comment"># 这步其实不是必须的，如果输出特征就是扁平的话</span></span><br><span class="line"></span><br><span class="line">pd.DataFrame(np.array(features_high_dim)).to_csv(<span class="string">'avg_pool_features.csv'</span>)</span><br></pre></td></tr></table></figure>
<p>何谓扁平？</p>
<p>一个张量的纬度是 d0 * d1 * d2 <em>…</em>dN<em>1 这样的，比如一个三维的数据可以是 100 </em> 30 * 20<em>1, 这个时候第0维是100，第1维是30，第2维是20。数据是一个立方体或超立方体的形象，我们把它拍平，这个时候数据就变成 60000 </em> 1的样子。</p>
<p>上面的栗子我们保留第0维，拍平剩下的纬度。</p>
<p>最后的1只是我随意加的，如果妨碍你理解可以去掉，如果能帮助你理解保留。</p>
<p>为什么是从第0维开始算。</p>
<h2 id="数据降纬">数据降纬</h2>
<p>做数据降维的目的一般有两个：<strong>压缩数据</strong> &amp; <strong>数据可视化</strong>。</p>
<p>我们这里是想看下数据到底可不可分（类），属于第二个。</p>
<p>我选取的算法是 <code>t-SNE</code>，当然还有其他算法，比如 <code>PCA</code> 什么的。</p>
<p>上一步我们截取 <code>XceptionNet</code> 最后 <code>FC</code> 层前一层的 <code>AVG_POOL</code> 输出是2028纬的，如此高纬的数据我们没发直观的感受数据到底是否可分，我们可以选择把它降到 2 -3 纬，下面是代码跟结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.manifold <span class="keyword">import</span> TSNE</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plot</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">features_high_dim = pd.read_csv(<span class="string">'avg_pool_features.csv'</span>)</span><br><span class="line"></span><br><span class="line">features_2_dim = TSNE(n_components=<span class="number">2</span>).fit_transform(np.array(features_high_dim.iloc[:, <span class="number">1</span>:<span class="number">-1</span>])) <span class="comment"># 因为前面没做处理，高纬数据的第一维是行号，最后一维是人物的id，这里去掉</span></span><br><span class="line"></span><br><span class="line">plot.scatter(features_2_dim[:, <span class="number">0</span>], features_2_dim[:, <span class="number">1</span>], c=label)</span><br><span class="line">plot.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/imgs/exception_pool_result.png" alt="exception_pool_result"><figcaption>exception_pool_result</figcaption>
</figure>
<p>我们看到数据有聚集在不同区域的趋势，所以可以认为这堆图片是可分，虽然分界线有些模糊。</p>
<h2 id="聚类分析">聚类分析</h2>
<p>可视化可以结合无监督学习来做，加个聚类算法上去，比如 <code>KMeans</code>。</p>
<p>上面的图片有点单调，我们随意加点色彩，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">nb_cluster = <span class="number">30</span> <span class="comment"># 随意指定30个类</span></span><br><span class="line"></span><br><span class="line">cluster = KMeans(n_clusters=nb_cluster)</span><br><span class="line">label = cluster.fit(features_2_dim).labels_</span><br><span class="line"></span><br><span class="line">plot.scatter(features_2_dim[:, <span class="number">0</span>], features_2_dim[:, <span class="number">1</span>], c=label) <span class="comment"># 加上分类标准</span></span><br><span class="line">plot.show()</span><br></pre></td></tr></table></figure>
<figure>
<img src="/imgs/exception_pool_result_30_cluster.png" alt="Kmeans分类结果"><figcaption>Kmeans分类结果</figcaption>
</figure>
<p>想看下分类的结果如何，我们可以根据上面<code>KMeans</code>给出的标签把图片移到不同的文件夹里。</p>
<p>像这样</p>
<p>佛系人生 <img src="/imgs/20180720111827.png" alt="佛系"></p>
<p>瞎jb拍风景 <img src="/imgs/20180720111931.png" alt="风景"></p>
<p>油腻的大叔 <img src="/imgs/20180720112015.png" alt="大叔"></p>
<p>猫猫狗狗 火箭？ <img src="/imgs/20180720112042.png" alt="动物、宠物"></p>
<p>效果还行，基本能把同类的归到一起🐶，这也验证了我开始的想法。</p>
<p>大部份人都没啥特别的，连他们的头像也是。</p>
<h2 id="结下来要做什么">结下来要做什么</h2>
<p>以上都是我用1000个样本做的事，接下来要多100w用户求特征做分类。按我机器的性能，提取一张图片的特征值需要1.2秒。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">100w * 1.2s = 120ws</span><br><span class="line"></span><br><span class="line">120ws / 3.6ks = 333.33h</span><br><span class="line"></span><br><span class="line">333.33h / 24h/t = 13.8t</span><br></pre></td></tr></table></figure>
<p>嗯,我的机器不吃不喝全干这件事要13.8天。</p>
<p>不说了，找boss开机器去</p>
<p>欢迎大家关注我的文章，后面会讲怎么微调模型直接产出分类。</p>

          
        
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Jjjeaswn Wong</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">4</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">3</span>
                    <span class="site-state-item-name">categories</span>
                  
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">7</span>
                    <span class="site-state-item-name">tags</span>
                  
                </div>
              
            </nav>
          

          

          

          
          

          
          

          
            
          
          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Jjjeaswn Wong</span>

  

  
</div>




  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> v3.7.1</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a class="theme-link" target="_blank" href="https://theme-next.org">NexT.Muse</a> v6.4.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    
	
    

    
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.4.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.4.0"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.4.0"></script>



  



  










  





  

  

  

  
  

  
  
    
      
        
      
    
      
    
      
    
      
    
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->

    
  


  
  

  

  

  

  

  

</body>
</html>
